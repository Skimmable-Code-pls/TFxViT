### Tensorflow notes
- [Keras's Self-Attention](https://github.com/keras-team/keras/blob/v3.3.3/keras/src/layers/attention/attention.py#L12-L15) is only for 1 Head.
- 
